# This script starts a local spark-shell on Mirko's MacBook
# 
# (1) Relevant JAR files from related projects are added to the Spark-Context
# (2) Services, which would be available in a distributed environment are started locally.
#

#
# This is the working environment for developing the Metadata capturing module for an 
# data focused knowledge management system.
#
# Our goal is to provide facts directly to Cloudera Navigator, and to SOLR collections.
#

#
# Remember where we did start the shell?
#
export here=$(pwd)

export SPARK_LOCAL_IP="127.0.0.1"
echo ---------------------------------------------------
echo ETOSCHA runner script - v1.0
echo ---------------------------------------------------
echo script started in : $here
echo ---------------------------------------------------

ls $here


##########################################################################################
# ADD JAR File for dspm-toolkit to the Spark-Shell
# 
#  Spark convenience tools:  		SparkShellUtilities.jar
#  Gephi-Toolkit for local raphs:  	gephi-toolkit-0.9.2-20170113.202843-77-all.jar"
#  ETOSHA-Profiler:      
export JARS="--jars /GITHUB/claerity-cloudera/XWARE42/shop-crawl/out/artifacts/any23_extractor_tool_jar/any23-extractor-tool.jar,/GITHUB/SparkShellUtilities/out/artifacts/s2u_jar/s2u.jar,/GITHUB/ETOSHA.WS/etosha/etosha-parent/etosha-profiler/out/artifacts/etosha_profiler_jar/etosha-profiler.jar,/sparkws/bin/gephi-toolkit-0.9.2-20170113.202843-77-all.jar"

zip -d /GITHUB/claerity-cloudera/XWARE42/shop-crawl/out/artifacts/any23_extractor_tool_jar/any23-extractor-tool.jar META-INF/*.RSA META-INF/*.DSA META-INF/*.SF
zip -d /GITHUB/ETOSHA.WS/etosha/etosha-parent/etosha-profiler/out/artifacts/etosha_profiler_jar/etosha-profiler.jar	 META-INF/*.RSA META-INF/*.DSA META-INF/*.SF






#
# You can use * for import all jars into a folder when adding in conf/spark-defaults.conf .
#
#spark.driver.extraClassPath /fullpath/*
#spark.executor.extraClassPath /fullpath/*



#
# Add missing JARs to local Maven repository 
#
#####mvn install:install-file -Dfile=/sparkws/bin/asm-3.2.jar -DgroupId=asm -DartifactId=asm -Dversion=3.2 -Dpackaging=jar

#
# Neo4J in local mode
#
/Users/kamir/bin/neo4j-enterprise-3.0.7/bin/neo4j start

#
# Etosha WebApp in local mode
#
cd /GITHUB/ETOSHA.WS/etosha/etosha-parent/etosha-webapp
mvn tomcat7:run-war &

#
# SOLR in cloud modus
#
# 
#   https://cwiki.apache.org/confluence/display/solr/Getting+Started+with+SolrCloud
#
#
#####/GITHUB/ETOSHA.WS/apache-solr-6.5.0/bin/solr start -c -m 1g -z localhost:2181 -a "-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=1044"
#####/GITHUB/ETOSHA.WS/apache-solr-6.5.0/bin/solr zk cp file:/GITHUB/claerity-cloudera/XWARE42/apache-solr-6.5.0/server/solr/shop_crawl/conf/schema.xml zk:/configs/shopCrawl/schema.xml -z localhost:9983

/GITHUB/ETOSHA.WS/apache-solr-6.5.0/bin/solr start -cloud -s /GITHUB/ETOSHA.WS/apache-solr-6.5.0/example/cloud/node1/solr -p 8983
open http://127.0.0.1:8080/etosha-webapp/
open http://127.0.0.1:8983
open http://localhost:7474/
open http://semanpix.de/opendata/wiki/index.php?title=Main_Page



ls $here
/Users/kamir/Downloads/spark-1.6.3-bin-hadoop2.6/bin/spark-shell --master local[6] --conf spark.executor.memory=14g $JARS --conf spark.jars.packages=com.lucidworks.spark:spark-solr:2.3.4,org.apache.kudu:kudu-spark_2.10:1.1.0,tdebatty:spark-knn-graphs:0.13,com.databricks:spark-avro_2.10:2.0.1,com.github.potix2:spark-google-spreadsheets_2.10:0.4.0,com.databricks:spark-csv_2.10:1.4.0 --repositories http://maven.restlet.org,http://bits.netbeans.org/maven2/,https://oss.sonatype.org/content/repositories/snapshots/,https://mvnrepository.com/artifact/asm/asm

/GITHUB/ETOSHA.WS/apache-solr-6.5.0/bin/solr stop
/Users/kamir/bin/neo4j-enterprise-3.0.7/bin/neo4j stop
ps -xa | grep tomcat

echo ---------------------------------------------------
echo Please Kill the maven process which started tomcat!
echo ---------------------------------------------------
echo ps -xa | grep tomcat





    



